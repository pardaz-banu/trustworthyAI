2025-02-22 03:52:46,496 INFO - helpers.log_helper - Completed configuring logger.
2025-02-22 03:52:46,496 INFO - __main__ - Python version is 3.12.7
2025-02-22 03:52:46,496 INFO - __main__ - Current commit of code: ___
2025-02-22 03:52:46,497 INFO - __main__ - Configuration parameters: {'encoder_type': 'TransformerEncoder', 'hidden_dim': 64, 'num_heads': 16, 'num_stacks': 6, 'residual': False, 'decoder_type': 'SingleLayerDecoder', 'decoder_activation': 'tanh', 'decoder_hidden_dim': 16, 'use_bias': False, 'use_bias_constant': False, 'bias_initial_value': False, 'batch_size': 64, 'input_dimension': 64, 'max_length': 12, 'data_size': 5000, 'read_data': True, 'data_path': 'input_data_path', 'normalize': False, 'transpose': True, 'score_type': 'BIC', 'reg_type': 'LR', 'lambda_iter_num': 1000, 'lambda_flag_default': True, 'score_bd_tight': True, 'lambda1_update': 1, 'lambda2_update': 10, 'score_lower': 0.0, 'score_upper': 0.0, 'lambda2_lower': -1, 'lambda2_upper': -1, 'seed': 8, 'nb_epoch': 20000, 'lr1_start': 0.001, 'lr1_decay_step': 5000, 'lr1_decay_rate': 0.96, 'alpha': 0.99, 'init_baseline': -1.0, 'temperature': 3.0, 'C': 10.0, 'l1_graph_reg': 0.0, 'inference_mode': True, 'restore_model': False, 'save_to': '20/model', 'restore_from': '20/model', 'log_dir': 'summary/20/repo', 'verbose': False, 'save_model_path': 'output/2025-02-22_03-52-46-495/model', 'summary_dir': 'output/2025-02-22_03-52-46-495/summary', 'plot_dir': 'output/2025-02-22_03-52-46-495/plot', 'graph_dir': 'output/2025-02-22_03-52-46-495/graph'}
2025-02-22 03:52:46,884 INFO - __main__ - Original sl: 1.8920581223061064, su: 7.27337148003996, strue: 3.121694481976613
2025-02-22 03:52:46,884 INFO - __main__ - Transfomed sl: 1.8920581223061064, su: 7.27337148003996, lambda2: 0.0001, true: 1.1425058140345163
2025-02-22 03:52:46,925 CRITICAL - helpers.log_helper - Unhandled exception
Traceback (most recent call last):
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/main.py", line 317, in <module>
    main()
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/main.py", line 119, in main
    actor = Actor(config)
            ^^^^^^^^^^^^^
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/models/actor_graph.py", line 59, in __init__
    self.build_permutation()
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/models/actor_graph.py", line 75, in build_permutation
    self.encoder_output = encoder(self.input_)
                          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/models/encoder/transformer_encoder.py", line 82, in call
    W_embed = self.add_weight(name="weights", shape=[1, self.input_dimension, self.input_embed], initializer=self.initializer)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: Exception encountered when calling TransformerEncoder.call().

[1mCould not automatically infer the output shape / dtype of 'transformer_encoder' (of type TransformerEncoder). Either the `TransformerEncoder.call()` method is incorrect, or you need to implement the `TransformerEncoder.compute_output_spec() / compute_output_shape()` method. Error encountered:

You cannot add new elements of state (variables or sub-layers) to a layer that is already built. All state must be created in the `__init__()` method or in the `build()` method.[0m

Arguments received by TransformerEncoder.call():
  â€¢ args=('<KerasTensor shape=(None, 12, 64), dtype=float32, sparse=False, name=keras_tensor>',)
  â€¢ kwargs=<class 'inspect._empty'>
2025-02-22 03:52:47,077 INFO - rpy2.rinterface_lib.embedded - Embedded R ended.
2025-02-22 03:52:47,078 INFO - rpy2.rinterface_lib.embedded - Embedded R already ended.
