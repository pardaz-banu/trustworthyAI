2025-02-22 04:08:31,430 INFO - helpers.log_helper - Completed configuring logger.
2025-02-22 04:08:31,430 INFO - __main__ - Python version is 3.12.7
2025-02-22 04:08:31,431 INFO - __main__ - Current commit of code: ___
2025-02-22 04:08:31,432 INFO - __main__ - Configuration parameters: {'encoder_type': 'TransformerEncoder', 'hidden_dim': 64, 'num_heads': 16, 'num_stacks': 6, 'residual': False, 'decoder_type': 'SingleLayerDecoder', 'decoder_activation': 'tanh', 'decoder_hidden_dim': 16, 'use_bias': False, 'use_bias_constant': False, 'bias_initial_value': False, 'batch_size': 64, 'input_dimension': 64, 'max_length': 12, 'data_size': 5000, 'read_data': True, 'data_path': 'input_data_path', 'normalize': False, 'transpose': True, 'score_type': 'BIC', 'reg_type': 'LR', 'lambda_iter_num': 1000, 'lambda_flag_default': True, 'score_bd_tight': True, 'lambda1_update': 1, 'lambda2_update': 10, 'score_lower': 0.0, 'score_upper': 0.0, 'lambda2_lower': -1, 'lambda2_upper': -1, 'seed': 8, 'nb_epoch': 20000, 'lr1_start': 0.001, 'lr1_decay_step': 5000, 'lr1_decay_rate': 0.96, 'alpha': 0.99, 'init_baseline': -1.0, 'temperature': 3.0, 'C': 10.0, 'l1_graph_reg': 0.0, 'inference_mode': True, 'restore_model': False, 'save_to': '20/model', 'restore_from': '20/model', 'log_dir': 'summary/20/repo', 'verbose': False, 'save_model_path': 'output/2025-02-22_04-08-31-430/model', 'summary_dir': 'output/2025-02-22_04-08-31-430/summary', 'plot_dir': 'output/2025-02-22_04-08-31-430/plot', 'graph_dir': 'output/2025-02-22_04-08-31-430/graph'}
2025-02-22 04:08:31,783 INFO - __main__ - Original sl: 1.8920581223061064, su: 7.27337148003996, strue: 3.121694481976613
2025-02-22 04:08:31,784 INFO - __main__ - Transfomed sl: 1.8920581223061064, su: 7.27337148003996, lambda2: 0.0001, true: 1.1425058140345163
2025-02-22 04:08:31,827 CRITICAL - helpers.log_helper - Unhandled exception
Traceback (most recent call last):
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/main.py", line 317, in <module>
    main()
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/main.py", line 119, in main
    actor = Actor(config)
            ^^^^^^^^^^^^^
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/models/actor_graph.py", line 59, in __init__
    self.build_permutation()
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/models/actor_graph.py", line 88, in build_permutation
    self.samples, self.scores, self.entropy = self.decoder.decode(self.encoder_output)
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pardazbanumohammad/trustworthyAI/research/Causal Discovery with RL/src/models/decoder/single_layer_decoder.py", line 32, in decode
    dot_l = tf.einsum('ijk, kl->ijl', encoder_output, W_l)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/common/keras_tensor.py", line 138, in __tf_tensor__
    raise ValueError(
ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:

```
x = Input(...)
...
tf_fn(x)  # Invalid.
```

What you should do instead is wrap `tf_fn` in a layer:

```
class MyLayer(Layer):
    def call(self, x):
        return tf_fn(x)

x = MyLayer()(x)
```

2025-02-22 04:08:31,946 INFO - rpy2.rinterface_lib.embedded - Embedded R ended.
2025-02-22 04:08:31,947 INFO - rpy2.rinterface_lib.embedded - Embedded R already ended.
